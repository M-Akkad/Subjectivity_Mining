{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d890959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade llama-cpp-python\n",
    "# !pip install openai\n",
    "# !pip install sse_starlette\n",
    "# !pip install starlette_context\n",
    "# !pip install pydantic_settings\n",
    "# !pip install \"fastapi[all]\"\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118aa129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from openai import OpenAI\n",
    "# # Point to the server\n",
    "# client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"cltl\")\n",
    "# # Sentences to classify\n",
    "# sentences = [\n",
    "# \"I hate you and I hope you fail.\",\n",
    "# \"What a beautiful day to go for a walk!\",\n",
    "# \"Your idea is stupid and nobody cares.\"\n",
    "# ]\n",
    "# # Build a single prompt\n",
    "# prompt = \"Classify each of the following sentences as 'hate' or 'non-hate':\\n\\n\"\n",
    "# for i, s in enumerate(sentences, 1):\n",
    "#     prompt += f\"{i}. {s}\\n\"\n",
    "    \n",
    "# prompt += \"\\nReturn the results in the format:\\n<number>. <label>\\n\"\n",
    "# # Make one request for all sentences\n",
    "# response = client.completions.create(\n",
    "#     model=\"local model\", # currently unused\n",
    "#     prompt=prompt,\n",
    "#     max_tokens=50,\n",
    "#     temperature=0,\n",
    "#     stop=[\"Classify\", \"\\n\\n\"]\n",
    "#     )\n",
    "# # Print the raw model output\n",
    "# print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cebed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3307549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "\n",
    "# Initialize OpenAI client pointing to local LLaMA server\n",
    "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"cltl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55782f5",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda32476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5852\n",
      "Test set size: 860\n",
      "Train label distribution:\n",
      "labels\n",
      "0    3591\n",
      "1    2261\n",
      "Name: count, dtype: int64\n",
      "Test label distribution:\n",
      "labels\n",
      "0    620\n",
      "1    240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv(r'Subjectivity_mining_assignment_4_5_data\\olid-train-small.csv')\n",
    "test_df = pd.read_csv(r'Subjectivity_mining_assignment_4_5_data\\OLID-test.csv')\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(f\"Train label distribution:\\n{train_df['labels'].value_counts()}\")\n",
    "print(f\"Test label distribution:\\n{test_df['labels'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa89c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5852 non-null   int64 \n",
      " 1   text    5852 non-null   object\n",
      " 2   labels  5852 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 137.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 860 entries, 0 to 859\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      860 non-null    int64 \n",
      " 1   text    860 non-null    object\n",
      " 2   labels  860 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 20.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215a76c",
   "metadata": {},
   "source": [
    "### Helper methodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(prompt):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=\"local model\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=10,\n",
    "            temperature=0,\n",
    "            stop=[\"\\n\", \"Text:\", \"Classification:\"]\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except:\n",
    "        return \"non-offensive\"\n",
    "\n",
    "def parse_response(response, use_toxic_labels=False):\n",
    "    response_lower = response.lower().strip()\n",
    "    \n",
    "    if use_toxic_labels:\n",
    "        if 'toxic' in response_lower and 'non-toxic' not in response_lower:\n",
    "            return 1\n",
    "        return 0\n",
    "    else:\n",
    "        if 'offensive' in response_lower and 'non-offensive' not in response_lower:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "def get_random_examples(n_examples):\n",
    "    n_per_class = n_examples // 2\n",
    "    \n",
    "    offensive = train_df[train_df['labels'] == 1].sample(n=n_per_class, random_state=42)\n",
    "    non_offensive = train_df[train_df['labels'] == 0].sample(n=n_per_class, random_state=42)\n",
    "    \n",
    "    examples = []\n",
    "    for _, row in offensive.iterrows():\n",
    "        examples.append((row['text'], 1))\n",
    "    for _, row in non_offensive.iterrows():\n",
    "        examples.append((row['text'], 0))\n",
    "    \n",
    "    random.shuffle(examples)\n",
    "    return examples\n",
    "\n",
    "def evaluate_prompts(test_df, predictions):\n",
    "    true_labels = test_df['labels'].tolist()\n",
    "    \n",
    "    report = classification_report(true_labels, predictions, \n",
    "                                   target_names=['Non-Offensive', 'Offensive'],\n",
    "                                   output_dict=True)\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    return report, cm\n",
    "\n",
    "def print_results(name, report, cm):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Strategy: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Macro F1: {report['macro avg']['f1-score']:.3f}\")\n",
    "    print(f\"Offensive F1: {report['Offensive']['f1-score']:.3f}\")\n",
    "    print(f\"Non-Offensive F1: {report['Non-Offensive']['f1-score']:.3f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"               Non-OFF  OFF\")\n",
    "    print(f\"Actual Non-OFF  {cm[0][0]:>6}  {cm[0][1]:>6}\")\n",
    "    print(f\"       OFF      {cm[1][0]:>6}  {cm[1][1]:>6}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21bee5",
   "metadata": {},
   "source": [
    "### VANILLA ZERO-SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6e4183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 1: VANILLA ZERO-SHOT\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Vanilla Zero-Shot\n",
      "============================================================\n",
      "Macro F1: 0.694\n",
      "Offensive F1: 0.564\n",
      "Non-Offensive F1: 0.825\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     506     114\n",
      "       OFF         101     139\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 1: VANILLA ZERO-SHOT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions_vanilla = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = f\"\"\"Classify the following text as 'offensive' or 'non-offensive':\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_vanilla.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_vanilla, cm_vanilla = evaluate_prompts(test_df, predictions_vanilla)\n",
    "print_results(\"Vanilla Zero-Shot\", report_vanilla, cm_vanilla)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c20033",
   "metadata": {},
   "source": [
    "### DEFINITION-AUGMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b7f016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 2: DEFINITION-AUGMENTED\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Definition-Augmented\n",
      "============================================================\n",
      "Macro F1: 0.693\n",
      "Offensive F1: 0.528\n",
      "Non-Offensive F1: 0.858\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     567      53\n",
      "       OFF         135     105\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 2: DEFINITION-AUGMENTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions_def = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = f\"\"\"Definitions:\n",
    "- Offensive: Contains insults, threats, profanity, or targets individuals/groups based on identity.\n",
    "- Non-offensive: Does not contain offensive language or harmful content.\n",
    "\n",
    "Classify the following text as 'offensive' or 'non-offensive':\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_def.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_def, cm_def = evaluate_prompts(test_df, predictions_def)\n",
    "print_results(\"Definition-Augmented\", report_def, cm_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456a97f",
   "metadata": {},
   "source": [
    "### ALTERNATIVE DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20864d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 3: ALTERNATIVE DEFINITION\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Alternative Definition (Harm-based)\n",
      "============================================================\n",
      "Macro F1: 0.718\n",
      "Offensive F1: 0.615\n",
      "Non-Offensive F1: 0.821\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     482     138\n",
      "       OFF          72     168\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 3: ALTERNATIVE DEFINITION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions_alt_def = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = f\"\"\"Definitions:\n",
    "- Offensive: Text that could cause harm, distress, or is intended to demean, dehumanize, or attack individuals or groups.\n",
    "- Non-offensive: Text that is respectful, neutral, or positive in nature.\n",
    "\n",
    "Classify the following text as 'offensive' or 'non-offensive':\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_alt_def.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_alt_def, cm_alt_def = evaluate_prompts(test_df, predictions_alt_def)\n",
    "print_results(\"Alternative Definition (Harm-based)\", report_alt_def, cm_alt_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3db35",
   "metadata": {},
   "source": [
    "### ALTERNATIVE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd382cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 4: ALTERNATIVE LABELS (toxic/non-toxic)\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Alternative Labels (Toxic)\n",
      "============================================================\n",
      "Macro F1: 0.737\n",
      "Offensive F1: 0.630\n",
      "Non-Offensive F1: 0.844\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     510     110\n",
      "       OFF          79     161\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 4: ALTERNATIVE LABELS (toxic/non-toxic)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions_toxic = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = f\"\"\"Definitions:\n",
    "- Toxic: Contains harmful, abusive, or hateful language.\n",
    "- Non-toxic: Does not contain harmful or abusive language.\n",
    "\n",
    "Classify the following text as 'toxic' or 'non-toxic':\n",
    "\n",
    "Text: {row['text']}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response, use_toxic_labels=True)\n",
    "    predictions_toxic.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_toxic, cm_toxic = evaluate_prompts(test_df, predictions_toxic)\n",
    "print_results(\"Alternative Labels (Toxic)\", report_toxic, cm_toxic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ced566",
   "metadata": {},
   "source": [
    "### FEW-SHOT RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68791173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 5a: FEW-SHOT RANDOM (2 examples)\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (2 examples)\n",
      "============================================================\n",
      "Macro F1: 0.672\n",
      "Offensive F1: 0.479\n",
      "Non-Offensive F1: 0.864\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     590      30\n",
      "       OFF         155      85\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT 5b: FEW-SHOT RANDOM (4 examples)\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (4 examples)\n",
      "============================================================\n",
      "Macro F1: 0.634\n",
      "Offensive F1: 0.413\n",
      "Non-Offensive F1: 0.856\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     591      29\n",
      "       OFF         170      70\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT 5c: FEW-SHOT RANDOM (6 examples)\n",
      "============================================================\n",
      "Processed 0/860\n",
      "Processed 100/860\n",
      "Processed 200/860\n",
      "Processed 300/860\n",
      "Processed 400/860\n",
      "Processed 500/860\n",
      "Processed 600/860\n",
      "Processed 700/860\n",
      "Processed 800/860\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (6 examples)\n",
      "============================================================\n",
      "Macro F1: 0.673\n",
      "Offensive F1: 0.491\n",
      "Non-Offensive F1: 0.856\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     574      46\n",
      "       OFF         147      93\n"
     ]
    }
   ],
   "source": [
    "# 5a: 2-shot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 5a: FEW-SHOT RANDOM (2 examples)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "examples_2 = get_random_examples(2)\n",
    "predictions_2shot = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = \"Classify texts as 'offensive' or 'non-offensive'.\\n\\nExamples:\\n\\n\"\n",
    "    \n",
    "    for ex_text, ex_label in examples_2:\n",
    "        label_str = \"offensive\" if ex_label == 1 else \"non-offensive\"\n",
    "        prompt += f\"Text: {ex_text}\\nClassification: {label_str}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Text: {row['text']}\\nClassification:\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_2shot.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_2shot, cm_2shot = evaluate_prompts(test_df, predictions_2shot)\n",
    "print_results(\"Few-Shot Random (2 examples)\", report_2shot, cm_2shot)\n",
    "\n",
    "# 5b: 4-shot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 5b: FEW-SHOT RANDOM (4 examples)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "examples_4 = get_random_examples(4)\n",
    "predictions_4shot = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = \"Classify texts as 'offensive' or 'non-offensive'.\\n\\nExamples:\\n\\n\"\n",
    "    \n",
    "    for ex_text, ex_label in examples_4:\n",
    "        label_str = \"offensive\" if ex_label == 1 else \"non-offensive\"\n",
    "        prompt += f\"Text: {ex_text}\\nClassification: {label_str}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Text: {row['text']}\\nClassification:\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_4shot.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_4shot, cm_4shot = evaluate_prompts(test_df, predictions_4shot)\n",
    "print_results(\"Few-Shot Random (4 examples)\", report_4shot, cm_4shot)\n",
    "\n",
    "# 5c: 6-shot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 5c: FEW-SHOT RANDOM (6 examples)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "examples_6 = get_random_examples(6)\n",
    "predictions_6shot = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    prompt = \"Classify texts as 'offensive' or 'non-offensive'.\\n\\nExamples:\\n\\n\"\n",
    "    \n",
    "    for ex_text, ex_label in examples_6:\n",
    "        label_str = \"offensive\" if ex_label == 1 else \"non-offensive\"\n",
    "        prompt += f\"Text: {ex_text}\\nClassification: {label_str}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Text: {row['text']}\\nClassification:\"\n",
    "    \n",
    "    response = get_prediction(prompt)\n",
    "    pred = parse_response(response)\n",
    "    predictions_6shot.append(pred)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_df)}\")\n",
    "\n",
    "report_6shot, cm_6shot = evaluate_prompts(test_df, predictions_6shot)\n",
    "print_results(\"Few-Shot Random (6 examples)\", report_6shot, cm_6shot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8c909",
   "metadata": {},
   "source": [
    "### SUMMARY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02bf5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "Strategy                                 Macro F1     OFF F1       NON-OFF F1  \n",
      "--------------------------------------------------------------------------------\n",
      "Vanilla Zero-Shot                        0.694        0.564        0.825       \n",
      "Definition-Augmented                     0.693        0.528        0.858       \n",
      "Alternative Definition                   0.718        0.615        0.821       \n",
      "Alternative Labels (Toxic)               0.737        0.630        0.844       \n",
      "Few-Shot Random (2 examples)             0.672        0.479        0.864       \n",
      "Few-Shot Random (4 examples)             0.634        0.413        0.856       \n",
      "Few-Shot Random (6 examples)             0.673        0.491        0.856       \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Strategy':<40} {'Macro F1':<12} {'OFF F1':<12} {'NON-OFF F1':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "all_results = [\n",
    "    (\"Vanilla Zero-Shot\", report_vanilla),\n",
    "    (\"Definition-Augmented\", report_def),\n",
    "    (\"Alternative Definition\", report_alt_def),\n",
    "    (\"Alternative Labels (Toxic)\", report_toxic),\n",
    "    (\"Few-Shot Random (2 examples)\", report_2shot),\n",
    "    (\"Few-Shot Random (4 examples)\", report_4shot),\n",
    "    (\"Few-Shot Random (6 examples)\", report_6shot)\n",
    "]\n",
    "\n",
    "for name, report in all_results:\n",
    "    macro_f1 = report['macro avg']['f1-score']\n",
    "    off_f1 = report['Offensive']['f1-score']\n",
    "    non_off_f1 = report['Non-Offensive']['f1-score']\n",
    "    print(f\"{name:<40} {macro_f1:<12.3f} {off_f1:<12.3f} {non_off_f1:<12.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17654241",
   "metadata": {},
   "source": [
    "### SAVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86731837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results saved to results_summary.json\n",
      "Experiment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "results_dict = {\n",
    "    'vanilla': {'report': report_vanilla, 'confusion_matrix': cm_vanilla.tolist()},\n",
    "    'definition': {'report': report_def, 'confusion_matrix': cm_def.tolist()},\n",
    "    'alt_definition': {'report': report_alt_def, 'confusion_matrix': cm_alt_def.tolist()},\n",
    "    'toxic_labels': {'report': report_toxic, 'confusion_matrix': cm_toxic.tolist()},\n",
    "    'few_shot_2': {'report': report_2shot, 'confusion_matrix': cm_2shot.tolist()},\n",
    "    'few_shot_4': {'report': report_4shot, 'confusion_matrix': cm_4shot.tolist()},\n",
    "    'few_shot_6': {'report': report_6shot, 'confusion_matrix': cm_6shot.tolist()}\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('results_summary.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(\"\\n\\nResults saved to results_summary.json\")\n",
    "print(\"Experiment completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1295593",
   "metadata": {},
   "source": [
    "### DETAILED ANALYSIS OF TWO STRATEGIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12c4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS OF ALL STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Strategy: Vanilla Zero-Shot\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.549\n",
      "  Recall:    0.579\n",
      "  F1-Score:  0.564\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.834\n",
      "  Recall:    0.816\n",
      "  F1-Score:  0.825\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     506     114\n",
      "       OFF         101     139\n",
      "\n",
      "============================================================\n",
      "Strategy: Definition-Augmented\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.665\n",
      "  Recall:    0.438\n",
      "  F1-Score:  0.528\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.808\n",
      "  Recall:    0.915\n",
      "  F1-Score:  0.858\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     567      53\n",
      "       OFF         135     105\n",
      "\n",
      "============================================================\n",
      "Strategy: Alternative Definition\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.549\n",
      "  Recall:    0.700\n",
      "  F1-Score:  0.615\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.870\n",
      "  Recall:    0.777\n",
      "  F1-Score:  0.821\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     482     138\n",
      "       OFF          72     168\n",
      "\n",
      "============================================================\n",
      "Strategy: Alternative Labels (Toxic)\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.594\n",
      "  Recall:    0.671\n",
      "  F1-Score:  0.630\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.866\n",
      "  Recall:    0.823\n",
      "  F1-Score:  0.844\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     510     110\n",
      "       OFF          79     161\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (2 examples)\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.739\n",
      "  Recall:    0.354\n",
      "  F1-Score:  0.479\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.792\n",
      "  Recall:    0.952\n",
      "  F1-Score:  0.864\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     590      30\n",
      "       OFF         155      85\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (4 examples)\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.707\n",
      "  Recall:    0.292\n",
      "  F1-Score:  0.413\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.777\n",
      "  Recall:    0.953\n",
      "  F1-Score:  0.856\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     591      29\n",
      "       OFF         170      70\n",
      "\n",
      "============================================================\n",
      "Strategy: Few-Shot Random (6 examples)\n",
      "============================================================\n",
      "\n",
      "Offensive Class Metrics:\n",
      "  Precision: 0.669\n",
      "  Recall:    0.388\n",
      "  F1-Score:  0.491\n",
      "\n",
      "Non-Offensive Class Metrics:\n",
      "  Precision: 0.796\n",
      "  Recall:    0.926\n",
      "  F1-Score:  0.856\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               Non-OFF  OFF\n",
      "Actual Non-OFF     574      46\n",
      "       OFF         147      93\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED ANALYSIS OF ALL STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_reports = [\n",
    "    (\"Vanilla Zero-Shot\", report_vanilla, cm_vanilla),\n",
    "    (\"Definition-Augmented\", report_def, cm_def),\n",
    "    (\"Alternative Definition\", report_alt_def, cm_alt_def),\n",
    "    (\"Alternative Labels (Toxic)\", report_toxic, cm_toxic),\n",
    "    (\"Few-Shot Random (2 examples)\", report_2shot, cm_2shot),\n",
    "    (\"Few-Shot Random (4 examples)\", report_4shot, cm_4shot),\n",
    "    (\"Few-Shot Random (6 examples)\", report_6shot, cm_6shot)\n",
    "]\n",
    "\n",
    "for strategy_name, report, cm in all_reports:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Strategy: {strategy_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nOffensive Class Metrics:\")\n",
    "    print(f\"  Precision: {report['Offensive']['precision']:.3f}\")\n",
    "    print(f\"  Recall:    {report['Offensive']['recall']:.3f}\")\n",
    "    print(f\"  F1-Score:  {report['Offensive']['f1-score']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nNon-Offensive Class Metrics:\")\n",
    "    print(f\"  Precision: {report['Non-Offensive']['precision']:.3f}\")\n",
    "    print(f\"  Recall:    {report['Non-Offensive']['recall']:.3f}\")\n",
    "    print(f\"  F1-Score:  {report['Non-Offensive']['f1-score']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"               Non-OFF  OFF\")\n",
    "    print(f\"Actual Non-OFF  {cm[0][0]:>6}  {cm[0][1]:>6}\")\n",
    "    print(f\"       OFF      {cm[1][0]:>6}  {cm[1][1]:>6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd038b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive\n",
      "\n",
      "Text:\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:8080/v1\", api_key=\"cltl\")\n",
    "\n",
    "text = \"I hate you and I hope you fail.\"\n",
    "\n",
    "prompt = f\"\"\"You are a content moderation classifier.\n",
    "\n",
    "Return EXACTLY one word: offensive OR non-offensive\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "r = client.completions.create(model=\"local\", prompt=prompt, max_tokens=6, temperature=0)\n",
    "print(r.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3265abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-toxic\n",
      "\n",
      "text:\n"
     ]
    }
   ],
   "source": [
    "text = \"What a beautiful day to go for a walk!\"\n",
    "\n",
    "prompt = f\"\"\"You are a content moderation classifier.\n",
    "\n",
    "Return EXACTLY one word: toxic OR non-toxic\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "r = client.completions.create(model=\"local\", prompt=prompt, max_tokens=6, temperature=0)\n",
    "label = r.choices[0].text.strip().lower()\n",
    "label = {\"toxic\":\"offensive\",\"non-toxic\":\"non-offensive\"}.get(label, label)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f776adc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You are stupid. Go away.', 'offensive\\n\\ntext:\\nthank'), ('Thanks for the update.', 'non-offensive\\n\\nexplanation:'), ('Nobody cares about your idea.', 'non-offensive\\n\\nexplanation:'), ('What a beautiful day!', 'non-offensive\\n\\ntext:')]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"You are stupid. Go away.\",\n",
    "    \"Thanks for the update.\",\n",
    "    \"Nobody cares about your idea.\",\n",
    "    \"What a beautiful day!\"\n",
    "]\n",
    "\n",
    "def classify(text):\n",
    "    prompt = f\"\"\"Return EXACTLY one word: offensive OR non-offensive\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    r = client.completions.create(model=\"local\", prompt=prompt, max_tokens=6, temperature=0)\n",
    "    return r.choices[0].text.strip().lower()\n",
    "\n",
    "preds = [classify(t) for t in texts]\n",
    "print(list(zip(texts, preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
